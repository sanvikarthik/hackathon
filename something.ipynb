{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'diabetes.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "data = data.drop(columns=['Income', 'Education'])\n",
    "\n",
    "X = data.drop(columns=['Diabetes_012'])\n",
    "y = data['Diabetes_012']\n",
    "\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n",
    "def predict_single_loop(x, w, b): \n",
    "    n = x.shape[0]\n",
    "    p = 0\n",
    "    for i in range(n):\n",
    "        p_i = x[i] * w[i]  \n",
    "        p = p + p_i         \n",
    "    p = p + b                \n",
    "    return p\n",
    "\n",
    "def predict(x, w, b): \n",
    "    p = np.dot(x, w) + b     \n",
    "    return p    \n",
    "\n",
    "def compute_cost(X, y, w, b): \n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b          \n",
    "        cost = cost + (f_wb_i - y[i])**2      \n",
    "    cost = cost / (2 * m)                     \n",
    "    return cost\n",
    "\n",
    "def compute_gradient(X, y, w, b): \n",
    "    m,n = X.shape          \n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_db, dj_dw = gradient_function(X, y, w, b)\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        if i < 100000:\n",
    "            J_history.append(cost_function(X, y, w, b))\n",
    "        if i % math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history\n",
    "\n",
    "n_features = X.shape[1]\n",
    "initial_w = np.zeros(n_features)\n",
    "initial_b = 0.0\n",
    "\n",
    "\n",
    "iterations = 1000\n",
    "alpha = 0.01\n",
    "\n",
    "w_final, b_final, J_hist = gradient_descent(X.values, y.values, initial_w, initial_b,\n",
    "                                            compute_cost, compute_gradient, alpha, iterations)\n",
    "\n",
    "predictions = np.dot(X, w_final) + b_final\n",
    "\n",
    "mse = np.mean((predictions - y) ** 2)\n",
    "\n",
    "print(f\"Final parameters: b = {b_final}, w = {w_final}\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
